{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from itertools import islice\n","import os\n","from pathlib import Path\n","import random\n","import sys\n","\n","import cv2\n","import imageio\n","import numpy as np\n","from tqdm.auto import tqdm\n","\n","from bbox import BBox\n","from colors import colors_panetone\n","from reader import TrackReader, Video_Detection\n","from utils import draw_detections, visualize_multi_cam\n","from video import Video, VideoSet\n","\n","# CONFIG. Change to your needs!\n","\n","# Path to the root of AIC20_track3 dataset\n","base_dir = Path(\"/data/AIC20_track3\")\n","# Path for storing the results\n","results_dir = Path(\"/home/malpunek/shit/m6results\")\n","\n","\n","# END CONFIG\n","\n","os.makedirs(results_dir, exist_ok=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Some function to get path to objects\n","\n","\n","def cam_dir(sequence, cam, train=True):\n","    return (\n","        base_dir / (\"train\" if train else \"test\") / f\"S{sequence:02d}\" / f\"c{cam:03d}\"\n","    )\n","\n","\n","def our_detection(seq, cam, method=\"mask_rcnn_ft\"):\n","    available_methods = [\"mask\", \"mask_rcnn_ft\", \"retinanet\", \"yolo\"]\n","    assert (\n","        method in available_methods\n","    ), f\"Please make sure method is one of {available_methods}\"\n","    return Path(\n","        f\"../detections_dl/s{seq:02d}/{method}/detections_{method}_c{cam:03d}_S{seq:02d}.txt\"\n","    )\n","\n","\n","def our_tracking(seq, cam, method=\"mask_rcnn_ft\"):\n","    available_methods = [\"mask\", \"mask_rcnn_ft\", \"retinanet\", \"yolo\"]\n","    assert (\n","        method in available_methods\n","    ), f\"Please make sure method is one of {available_methods}\"\n","    return Path(\n","        f\"../mtsc/detections_nn/S{seq:02d}/detections_{method}_c{cam:03d}_Overlap_S{seq:02d}.pkl\"\n","    )\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# (Un)distortion\n","seq, cam = 4, 35  # One of the few distorted cameras\n","work_dir = cam_dir(seq, cam)\n","\n","vid = Video(work_dir / \"vdo.avi\")\n","bbox = BBox(200, 200, 500, 500)\n","\n","dist = next(iter(vid.frames))\n","l, t, r, b = bbox.ltrb\n","cv2.rectangle(dist, (l, t), (r, b), [255, 0, 0])\n","\n","und = next(iter(vid))\n","l, t, r, b = bbox.undistorted(vid.camera_matrix, vid.distortion_coeffs).ltrb.astype(int)\n","cv2.rectangle(und, (l, t), (r, b), [255, 0, 0])\n","\n","cv2.imshow(\"DISTORTED\", dist)\n","cv2.imshow(\"UNDISTORTED\", und)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Init Single Camera\n","\n","seq, cam = 1, 1\n","work_dir = cam_dir(seq, cam)\n","\n","# Pick the detection and tracking\n","# detection = Video_Detection(work_dir / \"det\" / \"det_yolo3.txt\")\n","detection = Video_Detection(our_detection(seq, cam))\n","\n","# NOTE: the class named Video_Detection works also for tracking\n","# but, our tracks are stored as .pkl files\n","\n","# tracking = Video_Detection(work_dir / \"mtsc\" / \"mtsc_tc_mask_rcnn.txt\")\n","tracking = TrackReader(our_tracking(seq, cam))\n","\n","video_path = work_dir / \"vdo.avi\"\n","\n","vid = Video(video_path, detection_method=detection, tracking_method=tracking)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Detection\n","vid.eval_detection()\n","vid.dump_visualization(\n","    results_dir / \"our_detections.mp4\",\n","    detection,\n","    fps=1,\n","    begin=50,\n","    end=200,\n","    with_gt=True,\n",")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tracking\n","\n","vid.eval_tracking(tracking, iou_threshold=0.7)\n","vid.dump_visualization(\n","    results_dir / \"our_tracking.mp4\", tracking, fps=5, begin=50, end=200, with_gt=True\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Single-Camera Tracking With Map Visualization\n","\n","work_dir = cam_dir(1, 1)\n","\n","video_path = work_dir / \"vdo.avi\"\n","detection = Video_Detection(work_dir / \"gt\" / \"gt.txt\")\n","tracking = Video_Detection(work_dir / \"mtsc\" / \"mtsc_deepsort_yolo3.txt\")\n","\n","vid = Video(\n","    video_path, detection_method=detection, tracking_method=tracking, verbose=True\n",")\n","\n","vid.dump_visualized_map(\n","    results_dir / \"tracking_map.mp4\",\n","    50,\n","    300,\n","    fps=10,\n","    lasting=True,\n","    map_frame_shape=(400, 600),\n",")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Multi-Camera init\n","\n","# Pick a sequence\n","sequence = 1\n","\n","all_cameras_sequence = {\n","    1: list(range(1, 6)),\n","    3: list(range(10, 16)),\n","    4: list(range(16, 41)),\n","}\n","\n","cam_list = all_cameras_sequence[sequence]\n","work_dirs = [cam_dir(sequence, i) for i in cam_list]\n","video_paths = [wd / \"vdo.avi\" for wd in work_dirs]\n","gt_paths = [wd / \"gt\" / \"gt.txt\" for wd in work_dirs]\n","track_paths = [our_tracking(sequence, cam) for cam in cam_list]\n","\n","videos = [\n","    Video(vp, detection_method=Video_Detection(gtp), tracking_method=TrackReader(trp))\n","    for vp, gtp, trp in zip(video_paths, gt_paths, track_paths)\n","]\n","\n","vs = VideoSet(videos)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Multi-Camera tracking visualization without map\n","\n","it_frame = tqdm(islice(iter(vs), 200, 250), file=sys.stdout, total=50)\n","it_track = islice(vs.tracking(), 200, 250)\n","\n","writer = imageio.get_writer(results_dir / \"tracking_multi.mp4\", fps=2)\n","clrs = np.array(colors_panetone).tolist()\n","random.shuffle(clrs)\n","\n","for frame, tracks in zip(it_frame, it_track):\n","    frame = draw_detections(frame, tracks, colors=clrs)\n","    writer.append_data(frame)\n","\n","writer.close()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Multi-Camera evaluation\n","\n","vs.eval_tracking(use_encoding=False)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test Multi Cam Visualization\n","\n","\n","# If there's nothing on the minimap:\n","# For cameras 1-5 use:\n","#   - pix_per_10_meters=50\n","#   - shift=(0, 0)\n","# For others: chech the \"results / positions.txt\" file. And adjust\n","# these to so they fit within (0,0) x (400,400)\n","# pix_per_10_meters: 0.0001 degree is about 10 meters in reality.\n","#     This param sets how big is the differenve of 10 meters on minimap\n","# shift: cameras 16-40 are mostly located far from the center of the scenario\n","#     Look at the file save_map_positions. It's a mapping from obj_id into\n","#     mini-map positions.\n","\n","visualize_multi_cam(\n","    results_dir / \"multi_cam_vis.mp4\",\n","    vs,\n","    begin=0,\n","    end=300,\n","    save_map_positions=results_dir / \"positions.txt\",\n","    pix_per_10_meters=5,\n","    map_shift=(0, 0),\n",")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}